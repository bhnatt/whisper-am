{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31352d1f-97cc-4a22-a378-efc2a5817b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Cloning into 'whisper-cloab-am'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (3/3), done.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q git+https://github.com/openai/whisper.git\n",
    "%pip install -q python-docx\n",
    "!git clone https://github.com/bhnatt/whisper-colab-am.git\n",
    "\n",
    "#https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1aaa0dc7-0f88-4ff7-8aac-5216408461fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('whisper-colab-am')\n",
    "\n",
    "from whisper_am import WhisperAM, mountDrive\n",
    "from whisper_utils import write_txt, write_srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "800cba55-39ad-45a5-b5f1-9df55ca5171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/data/\n",
      "init\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/'\n",
    "\n",
    "ds = mountDrive ()\n",
    "google_drive = '/content/drive/MyDrive/' if ds else './'\n",
    "\n",
    "data_path   = google_drive + data_dir   #@param {type:\"string\"}\n",
    "print (data_path)\n",
    "\n",
    "model_name = 'tiny.en' #@param [\"medium.en\", \"large\", \"tiny.en\"]\n",
    "\n",
    "am = WhisperAM (model_name, data_path)\n",
    "am.checkCuda ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f49f307-6970-4e2e-a104-83087a691b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/dream.mp3']\n",
      "dream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwchoi/miniconda3/envs/stt/lib/python3.10/site-packages/whisper/transcribe.py:76: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dream \n",
      "  I have the pleasure to present to you, Dr. Martin ... st, thank God Almighty, we are free at last. Amen.\n"
     ]
    }
   ],
   "source": [
    "am.run ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a139d-d3bb-4b2e-b942-f787edb94e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt",
   "language": "python",
   "name": "stt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
